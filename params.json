{"name":"Bc-zip","tagline":"Bicriteria Data Compressor","body":"# **bc-zip** - Bicriteria Data Compressor\r\n\r\n## Introduction\r\n\r\n*bc-zip* is a lossless, general-purpose, *optimizing* data compressor.\r\n\r\nIt can be used to compress a file in order to achieve the *best* compression ratio. More technically, bc-zip computes the most succinct Lempel-Ziv parsing, which is the same scheme used by gzip, Snappy, LZO, and LZ4. It goes without saying that compressed files are considerably smaller when compressed with bc-zip than with the aforementioned compressors.\r\n\r\nMoreover, and more importantly, bc-zip can be used to obtain a compressed file such that the *decompression time is below a user-specified time and the compression ratio is maximized*, and the other way round (compression size bounded, decompression speed maximized).  In this way, it is possible to achieve very good compression ratios *and* decompression speeds comparable or better than those achieved by state-of-the-art compressors Snappy and LZ4. Even better, it is possible to specify the decompression speed dictated by your application requirements, and let bc-zip automatically achieve the highest compression ratio with that constraint.\r\n\r\nThis is achieved through an innovative way of modeling data compression as an optimization problem, along with the use of a decompression time model which accurately estimates the decompression time of a compressed file.\r\n\r\nFor some experimental results backing those claims or more background about the science behind it, visit the dedicated webpage at http://acube.di.unipi.it/bc-zip/\r\n\r\n## Compiling\r\n\r\nbc-zip requires the following components:\r\n\r\n- cmake\r\n- A C++11-enabled compiler (g++ 4.7+, clang 3.2+, ICC 11+)\r\n- Boost (uBLAS, program_options)\r\n- A POSIX environment\r\n\r\nThe project is compiled like any standard CMake project:\r\n\r\n- cd into the project's directory\r\n- mkdir build\r\n- cd build\r\n- cmake ../\r\n- make\r\n\r\n## Usage\r\n\r\nThe executable is invoked with the following syntax:\r\n\r\n\t./bc-zip command <command-specific options>\r\n\r\nThe most interesting commands are the following:\r\n\r\n- **bit-optimal:**\tcompress the file so compresson ratio is maximized\r\n- **compress:**\t\toptimize one resource (decompression speed, compression ratio) given a bound on the other one.\r\n- **decompress:** \tdecompress a file \r\n\r\nThere are also two commands, namely encoders and gens, which we will illustrate later in this document.\r\n\r\n### bit-optimal\r\n\r\nWe report the most important options (bold options are compulsory). For others, have a look at the command-line help \r\n(just type bc-zip bit-optimal to show the help).\r\n\r\n| Option \t\t| Meaning \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t|\r\n|---------------|---------------------------------------------------------------------------------------------------|\r\n| **-i file**\t| \tFile to be compressed. Can also be specified by the first positional argument.\r\n| **-o file**\t| \tFilename of compressed output. Can also be specified by the second positional argument.\r\n| **-e encoder**| \tInteger encoder used in compression. A list of all supported encoders can be retrieved by invoking the bc-zip command \"encoders\". We suggest to pick one among **soda09_16** (succinct, relatively slow at decompression) and **hybrid-16** (less succinct, very fast decompression speeds).\r\n| -b bucket \t|\tLogically splits the input file into blocks of bucket megabytes, compresses them individually and then concatenate them to obtain the final compressed file. Lowers compression time at the expense of optimality and, thus, compression ratio.\r\n| -z \t\t\t|\tShows a progress bar while compressing.\r\n\r\n**Example**:\r\n\r\n\t./bc-zip bit-optimal input output.lzo -e hybrid-16 -b 64\r\n\r\nCompress file *input* into *output.lzo*, using the fast encoder *hybrid-16*, with buckets of 64 megabytes.\r\n\r\n\t./bc-zip bit-optimal input output.lzo -e soda09_16 -z\r\n\r\nOptimally compress file *input* into *output.lzo*, using the succinct encoder *soda09_16*.\r\n\r\n### compress\r\n\r\nCompress implements \"bicriteria\" compression.\r\nIn order to evaluate decompression times, a **target** file encoding the decompression time model for the target machine (that is, the machine in which decompression will take place) is required. Have a look at section **Target file** for more informations about this matter.\r\n\r\nIn the following we illustrate the most important options (bold options are compulsory).\r\n\r\n| Option \t\t| Meaning \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t|\r\n|---------------|---------------------------------------------------------------------------------------------------|\r\n|**-i file**\t| File to be compressed. Can also be specified by the first positional argument.\r\n|**-e encoder**\t| Integer encoder used in compression. A list of all supported encoders can be retrieved by invoking the bc-zip command \"encoders\". We suggest to pick one among **soda09_16** (succinct, relatively slow at decompression) and **hybrid-16** (less succinct, very fast decompression speeds).\r\n|**-t target**\t| Specify the target machine model file, as obtained by the calibrator tool (see the section about the calibrator for further informations), WITHOUT the .tgt suffix. That is, if the model is names X.tgt, then just pass X to this option.\r\n|**-b bound**\t| Specify the compression bound. If the bound has the form Xk, then the compression size will be at most X kilobytes and the decompression time minimized. If the bound has the form Xm, then the  decompression time will be at most X milliseconds (according to the target model specified with  option -t ) and compressed size minimized. Multiple bounds can be specified by separating different bounds with a comma: in this case the file will be compressed multiple times, once for each bound.\r\n|-l level \t\t| Specify a compression level (float in range [0,1]), which might be in compression space or  decompression time. A compression level is a \"relative\" way of setting bounds. A level in the form XS (such as 0.5S) defines a bound on the compression space. It means that, if the most space-succinct compressed file for the input file has space S_1, and the compressed file with the highest decompression speed has space S_2 (with S_1 < S_2), then the level specifies a bound on compressed space equal to S_1 + X * (S_2 - S_1). In other words, compressing a file with level 0S is the same as compressing the file with the bit-optimal command, while compressing a file with level 1S instructs the compressor to obtain the decompression time-optimal compression file. Linearly increasing the level increases linearly the compressed space of the final parsing. A level in the form XT (such as 0.2T) similarly defines a bound on the decompression time, so a level of 0T obtains the compression with the lowest decompression time, while a level of 1T obtains the most succinct compressed file. A level of 0.5T has a decompression time which is a mean of the decompression time of the most succinct compressed file and the decompression time of the compressed file with the highest decompression speed. Multiple levels can be specified by separating different bounds with a comma: in this case the file will be compressed multiple times, once for each level.\r\n|-z \t\t\t| Shows a progress bar while compressing.\r\n\r\nAt least one among -b or -l must be selected. The output file name is a combination of the input file name and the compression options specified.\r\n\r\n**Examples**\r\n\r\nSuppose you have a file input.txt to be compressed and a target file smartphone.tgt, which models the decompression time of a compressed file\r\non a particular smartphone.\r\nSuppose the most succinct compressed file has a decompression time of 600 msec (with encoder hybrid-16) and takes 200MB, while the fastest compressed file is decompressed in 300msec (also with encoder hybrid-16) and takes 400MB of space.\r\nThen:\r\n\r\n\t./bc-zip compress input.txt -e hybrid-16 -t smartphone -b 300000k -z\r\n\r\nCompress file *input.txt* with encoder *hybrid-16*, obtaining the fastest compressed file which is not greater than 300 megabytes (300,000 kilobytes), showing a progress bar during the process. The compressed file is input.txt#hybrid-16#300MB.lzo.\r\n\r\n\t./bc-zip compress input.txt -e soda09_16 -t smartphone -b 300000k,600m\r\n\r\nCompress file *input.txt* two times with encoder *soda09_16*: the first time with a bound of 300MB in space, saving in input.txt#soda09_16#300MB.lzo; the second with a time bound of 600 msecs (according to model *smartphone.tgt*, stored in the calling directory), saving in input.txt#soda09_16#600msec.lzo\r\n\r\n\t./bc-zip compress input.txt -e hybrid-16 -t smartphone -l 0.5T,0.1T,0.1S -b 300000k\r\n\r\nCompress file input.txt four times:\r\n- first time with a level of 0.5T, so with a time bound of 450 msec (remmber the assumptions made at the beginning), saving in input.txt#hybrid-16#0.5T.lzo\r\n- second time with a level of 0.1T, so with a time bound of 330 msec, saving in input.txt#hybrid-16#0.5T.lzo\r\n- third time with a level of 0.1S, so with a space bound of 220MB, saving in input.txt#hybrid-16#0.1S.lzo\r\n- fourth time with a bound of 300MB, saving in input.txt#hybrid-16#300MB.lzo\r\n\r\n### decompress\r\n\r\nUsage: bc-zip decompress input_file output_file\r\n\r\n**Example**\r\n\r\n\t./bc-zip decompress compressed.lzo original\r\n\r\nDecompress file \"compressed.lzo\" into file \"original\".\r\n\r\n## Target file\r\n\r\n### What it is and why it's needed?\r\n\r\nDifferent machines decompress the same file with different decompression times. So, in order to properly compute the decompression time of a compressed file for a given target machine, *bc-zip* needs a decompression time model tuned for that target machine (which may be different than the machine used in compression!).\r\n\r\nbc-zip does not ship with any decompression time model by default. Instead, bc-zip needs a *target file* when it is invoked with the \"compress\" command.\r\n\r\nA target file is a small, human-readable file which encodes the decompression time model for a particular machine.\r\n\r\n\r\n### How do I get it?\r\n\r\nA target file can be obtained in an automatic or semi-automatic fashion through the use of the provided *calibrator* tool.\r\n\r\nA calibrator obtains the target file of the machine in which it is executed.\r\n\r\nThe calibrator tool is composed of two objects: a shell script **calibrator.sh** and an executable **calibrator**, both located in the tool/ directory.\r\n\r\nThe user must invoke the shell script, taking care of having both the shell script and the executable on the same directory.\r\n\r\nThe tool is invoked as follows:\r\n\r\n\t./calibrator.sh \t<target name> <memory hierarchy descriptor>\r\n\r\nWhere:\r\n- **target name**: the name of that particular machine. If X is passed, the outputted target file will be named X.tgt.\r\n- **memory hierarchy descriptor**: A file with a line for each memory level (e.g. L1 and L2 caches, main memory), sorted by capacity, with just two fields for each line separated by some space: level capacity, in kilobytes, and latency, in nanoseconds.\r\n\r\nA valid memory hierarchy descriptor could be the following:\r\n\r\n```\r\n32 \t\t\t\t0.41\r\n256 \t\t\t1.2\r\n6144\t\t\t3.3\r\n4294967296\t\t80\r\n```\r\n\r\nWhich means that that particular machine has a L1 cache of 32KB with access latency of 0.4ns, a 256kb L2 cache with latency 1.2ns, a L3 cache with latency 3.3 and a main memory of 4GB with latency of 80ns.\r\n\r\nThis file can also be generated automatically via the get_latencies tool, which can be invoked in the following way:\r\n\r\n\t./get_latencies lmbench_file\r\n\r\nWhere lmbench_file is the output of tool lat_mem_rd in the LMBench3 suite (downloadable at the following url: http://www.bitmover.com/lmbench/get_lmbench.html).\r\n\r\n**Example**\r\n\r\n\t./calibrator client client_hierarchy.txt\r\n\r\nObtains the target file client.tgt of the machine in which it is executed, provided that client_hierarchy.txt properly describes the memory hierarchy of that machine.\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}